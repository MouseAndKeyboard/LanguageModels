{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58c65174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c44d7",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1aea7",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4eae6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    train = pd.read_csv(f'./data/{name}-train.csv')\n",
    "    test = pd.read_csv(f'./data/{name}-test.csv')\n",
    "    val = pd.read_csv(f'./data/{name}-val.csv')\n",
    "    return train, test, val\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb4251d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = load_data('task_2')\n",
    "#x_train_tensor = torch.as_tensor(x_data).float()\n",
    "#y_train_tensor = torch.as_tensor(y_truth).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e11cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.job_description\n",
    "train_y = train.category.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36279653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Banking & Financial Services', 'Manufacturing, Transport & Logistics', 'Community Services & Development', 'Healthcare & Medical', 'Insurance & Superannuation', ..., 'Call Centre & Customer Service', 'Marketing & Communications', 'Advertising, Arts & Media', 'CEO & General Management', 'Real Estate & Property']\n",
       "Length: 30\n",
       "Categories (30, object): ['Accounting', 'Administration & Office Support', 'Advertising, Arts & Media', 'Banking & Financial Services', ..., 'Science & Technology', 'Self Employment', 'Sport & Recreation', 'Trades & Services']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dd3b4",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39110f",
   "metadata": {},
   "source": [
    "## Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e18e61c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'set_seed_everywhere' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel_state_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39msave_dir,\n\u001b[1;32m     37\u001b[0m                                          args\u001b[38;5;241m.\u001b[39mmodel_state_file)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Set seed for reproducibility\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mset_seed_everywhere\u001b[49m(args\u001b[38;5;241m.\u001b[39mseed, args\u001b[38;5;241m.\u001b[39mcuda)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# handle dirs\u001b[39;00m\n\u001b[1;32m     43\u001b[0m handle_dirs(args\u001b[38;5;241m.\u001b[39msave_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'set_seed_everywhere' is not defined"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    surname_csv=\"../data/surnames/surnames_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/surname_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=64,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2f7b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Banking & Financial Services', 'Manufacturing, Transport & Logistics', 'Community Services & Development', 'Healthcare & Medical', 'Insurance & Superannuation']\n",
    "\n",
    "class ElmanRNN(nn.Module):\n",
    "    \"\"\" an Elman RNN built using the RNNCell \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_first=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): size of the input vectors\n",
    "            hidden_size (int): size of the hidden state vectors\n",
    "            bathc_first (bool): whether the 0th dimension is batch\n",
    "        \"\"\"\n",
    "        super(ElmanRNN, self).__init__()\n",
    "        \n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def _initial_hidden(self, batch_size):\n",
    "        return torch.zeros((batch_size, self.hidden_size))\n",
    "\n",
    "    def forward(self, x_in, initial_hidden=None):\n",
    "        \"\"\"The forward pass of the ElmanRNN\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                If self.batch_first: x_in.shape = (batch, seq_size, feat_size)\n",
    "                Else: x_in.shape = (seq_size, batch, feat_size)\n",
    "            initial_hidden (torch.Tensor): the initial hidden state for the RNN\n",
    "        Returns:\n",
    "            hiddens (torch.Tensor): The outputs of the RNN at each time step. \n",
    "                If self.batch_first: hiddens.shape = (batch, seq_size, hidden_size)\n",
    "                Else: hiddens.shape = (seq_size, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_size, feat_size = x_in.size()\n",
    "            x_in = x_in.permute(1, 0, 2)\n",
    "        else:\n",
    "            seq_size, batch_size, feat_size = x_in.size()\n",
    "    \n",
    "        hiddens = []\n",
    "\n",
    "        if initial_hidden is None:\n",
    "            initial_hidden = self._initial_hidden(batch_size)\n",
    "            initial_hidden = initial_hidden.to(x_in.device)\n",
    "\n",
    "        hidden_t = initial_hidden\n",
    "                    \n",
    "        for t in range(seq_size):\n",
    "            hidden_t = self.rnn_cell(x_in[t], hidden_t)\n",
    "            hiddens.append(hidden_t)\n",
    "            \n",
    "        hiddens = torch.stack(hiddens)\n",
    "\n",
    "        if self.batch_first:\n",
    "            hiddens = hiddens.permute(1, 0, 2)\n",
    "\n",
    "        return hiddens\n",
    "\n",
    "\n",
    "\n",
    "class JobCategoryClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, batch_first=True, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): The size of the character embeddings\n",
    "            num_embeddings (int): The number of characters to embed\n",
    "            num_classes (int): The size of the prediction vector \n",
    "                Note: the number of nationalities\n",
    "            rnn_hidden_size (int): The size of the RNN's hidden state\n",
    "            batch_first (bool): Informs whether the input tensors will \n",
    "                have batch or the sequence on the 0th dimension\n",
    "            padding_idx (int): The index for the tensor padding; \n",
    "                see torch.nn.Embedding\n",
    "        \"\"\"\n",
    "        super(JobCategoryClassifier, self).__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)\n",
    "        self.rnn = ElmanRNN(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,\n",
    "                             batch_first=batch_first)\n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                         out_features=rnn_hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size,\n",
    "                          out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            x_lengths (torch.Tensor): the lengths of each sequence in the batch.\n",
    "                They are used to find the final vector of each sequence\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        x_embedded = self.emb(x_in)\n",
    "        y_out = self.rnn(x_embedded)\n",
    "\n",
    "        if x_lengths is not None:\n",
    "            y_out = column_gather(y_out, x_lengths)\n",
    "        else:\n",
    "            y_out = y_out[:, -1, :]\n",
    "\n",
    "        y_out = F.relu(self.fc1(F.dropout(y_out, 0.5)))\n",
    "        y_out = self.fc2(F.dropout(y_out, 0.5))\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "\n",
    "        return y_out\n",
    "        \n",
    "class RNNWrapper():\n",
    "    def __init__(self, vectorizer, dataset):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = JobCategoryClassifier(\n",
    "                                embedding_size=args.char_embedding_size, \n",
    "                                num_embeddings=len(vectorizer.char_vocab),\n",
    "                                num_classes=len(CATEGORIES),\n",
    "                                rnn_hidden_size=args.rnn_hidden_size,\n",
    "                                padding_idx=vectorizer.char_vocab.mask_index)\n",
    "        \n",
    "    def train(self):\n",
    "        # USED FOR IMBALANCED DATA:::::\n",
    "        # loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "        # :::::::\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=args.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                   mode='min', factor=0.5,\n",
    "                                                   patience=1)\n",
    "        \n",
    "        for epoch_index in range(args.num_epochs):\n",
    "            # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "            batch_generator = generate_batches(x, \n",
    "                                               batch_size=args.batch_size, \n",
    "                                               device=args.device)\n",
    "            \n",
    "            self.model.train()\n",
    "            for batch_index, batch_dict in enumerate(batch_generator):\n",
    "                # the training routine is these 5 steps:\n",
    "\n",
    "                # --------------------------------------    \n",
    "                # step 1. zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # step 2. compute the output\n",
    "                y_pred = self.model(x_in=batch_dict['x_data'], \n",
    "                                    x_lengths=batch_dict['x_length'])\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "\n",
    "                #running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # step 4. use loss to produce gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # step 5. use optimizer to take gradient step\n",
    "                optimizer.step()\n",
    "                # -----------------------------------------\n",
    "                # compute the accuracy\n",
    "#                 acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "#                 running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "#                 # update bar\n",
    "#                 train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "#                 train_bar.update()\n",
    "            \n",
    "    \n",
    "    def test(self):\n",
    "        pass\n",
    "    \n",
    "    def classify(self, pmf):\n",
    "        \"\"\"\n",
    "            pmf is a vector of probabilities over the different categories\n",
    "            picks the most likely category\n",
    "        \"\"\"\n",
    "        return CATEGORIES[np.argmax(pmf)]\n",
    "    \n",
    "    def interact(self):\n",
    "        sentence = input(\"Input: \")\n",
    "        y_hat = self.model(sentence)\n",
    "        result = self.classify(y_hat)\n",
    "        print(f\"Model prediction: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f51534ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m rnn_model_our_embeddings \u001b[38;5;241m=\u001b[39m RNNWrapper(our_embeddings_vec, multiclass_dataset)\n\u001b[1;32m     13\u001b[0m rnn_model_pretrained \u001b[38;5;241m=\u001b[39m RNNWrapper(pretrained_embeddings_vec, multiclass_dataset)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrnn_model_one_hot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m rnn_model_our_embeddings\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m rnn_model_pretrained\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Input \u001b[0;32mIn [98]\u001b[0m, in \u001b[0;36mRNNWrapper.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# USED FOR IMBALANCED DATA:::::\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# loss_func = nn.CrossEntropyLoss(dataset.class_weights)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# :::::::\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m--> 134\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m    135\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    136\u001b[0m                                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    137\u001b[0m                                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;66;03m# setup: batch generator, set loss and acc to 0, set train mode on\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "#multiclass_dataset = OurDataset(path)\n",
    "multiclass_dataset = None\n",
    "\n",
    "#one_hot_vec = OneHotVectorizor(dataset=multiclass_dataset)\n",
    "#our_embeddings_vec = OurW2VVectorizor(dataset=multiclass_dataset)\n",
    "#pretrained_embeddings_vec = PretrainedW2VVectorizor(dataset=multiclass_dataset)\n",
    "one_hot_vec = None\n",
    "our_embeddings_vec = None\n",
    "pretrained_embeddings_vec = None\n",
    "\n",
    "rnn_model_one_hot = RNNWrapper(one_hot_vec, multiclass_dataset)\n",
    "rnn_model_our_embeddings = RNNWrapper(our_embeddings_vec, multiclass_dataset)\n",
    "rnn_model_pretrained = RNNWrapper(pretrained_embeddings_vec, multiclass_dataset)\n",
    "\n",
    "rnn_model_one_hot.train()\n",
    "rnn_model_our_embeddings.train()\n",
    "rnn_model_pretrained.train()\n",
    "\n",
    "rnn_model_one_hot.test()\n",
    "rnn_model_our_embeddings.test()\n",
    "rnn_model_pretrained.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ed15d",
   "metadata": {},
   "source": [
    "### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b65e5dce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minteract\u001b[49m(rnn_model_one_hot)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interact' is not defined"
     ]
    }
   ],
   "source": [
    "interact(rnn_model_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b131e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minteract\u001b[49m(rnn_model_our_embeddings)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interact' is not defined"
     ]
    }
   ],
   "source": [
    "interact(rnn_model_our_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d2e4445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minteract\u001b[49m(rnn_model_pretrained)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interact' is not defined"
     ]
    }
   ],
   "source": [
    "interact(rnn_model_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071c10a",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00e7e518",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f0bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
